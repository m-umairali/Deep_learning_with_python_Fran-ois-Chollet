{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2, Basic Building Blocks of Neural Network (Math Intuition)\n",
    "\n",
    "It is necessary to learn mathematics in order to be a deep learning engineer. Without math, it will become hard to identify and resolve the issues, you will face in the deep learning architecture. \n",
    "So here we gonna start with the hello world of deep learning which is “MNIST”. MNIST (National Institute  of standards and Technology) has developed this dataset in 1980s. This dataset consist of handwritten 60,000 training and 10,000 test images categorized through 0 to 9. Here we will classify grayscale images using Keras. This comes along with the installation of Keras. \n",
    "Note: In machine learning a category in a classification problem is called a class.Data points called samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 17s 2us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code imports the MNIST dataset from the TensorFlow Keras library, which is a high-level API for building and training machine learning models. Specifically, the code imports the `mnist` module from the `datasets` subpackage of the `tensorflow.keras` library.\n",
    "\n",
    "The second line of the code uses the `load_data()` function from the MNIST module to load the dataset into two sets of variables: `train_images` and `train_labels` for the training data, and \"test_images\" and \"test_labels\" for the test data.\n",
    "\n",
    "The training data consists of 60,000 images and their corresponding labels, while the test data consists of 10,000 images and their corresponding labels. The images are represented as NumPy arrays with shape (28, 28) ranging from 0 to 9, while the labels are represented as NumPy arrays of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output (10000,) for ``test_labels.shape`` indicates that test_labels is a ``1-dimensional`` NumPy array with 10,000 elements.\n",
    "\n",
    "Since the MNIST test set contains 10,000 images, each image is associated with a single label. Therefore, the test_labels array contains the corresponding label for each image in the test set.\n",
    "\n",
    "The shape of the test_labels array is (10000,), which means that it has a length of 10,000. The lack of a second dimension in the shape indicates that test_labels is a 1D array. This is in contrast to the test_images array, which has a shape of (10000, 28, 28) indicating that it is a 3D array with 10,000 28x28 images.\n",
    "\n",
    "Overall, the (10000,) output indicates the shape of the test_labels array and confirms that it contains 10,000 labels for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation = 'relu'),     \n",
    "    layers.Dense(10, activation = 'softmax')\n",
    "- Core building block of neural network is layer\n",
    "- Our model consist of two dense layers (densly connected or fully connected)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core building block of neural network is layer and our model consist of two dense layers (densly connected or fully connected)\n",
    "\n",
    "- By importing the `layers` module from TensorFlow Keras, you can access all of these layer types and more. For example, `layers.Dense` is used to define fully connected layers in a neural network, while `layers.Conv2D` is used to define convolutional layers.\n",
    "\n",
    "- When using `keras.Sequential`, you can add layers. Each layer in the sequence is connected to the previous layer, forming a chain of operations that process the input data, where the output of one layer is fed as input to the next layer in the sequence., and so on, until the final layer produces the output of the model. \n",
    "\n",
    "`layers.Dense(512, activation = 'relu')` defines the first dense layer in the model. The Dense layer is a fully connected layer where each neuron is connected to every neuron in the previous layer. The first argument 512 specifies the number of neurons in this layer. The activation argument specifies the activation function used by this layer, which in this case is the ReLU function. ReLU is a commonly used activation function that **returns the input if it is positive, and zero otherwise.**\n",
    "\n",
    "`layers.Dense(10, activation = 'softmax')` defines the second dense layer in the model. The second layer is also a fully connected layer with 10 neurons, but the activation function used in this layer is the Softmax function. Softmax is another commonly used activation function that converts the outputs of the previous layer into a probability distribution over the 10 possible classes in the MNIST dataset.\n",
    "\n",
    "- The two Dense layers are enclosed within square brackets [] and passed as a list to the Sequential model constructor. This specifies the order of layers in the neural network.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the model ready for training, we need to pick three more things as part of\n",
    "the compilation step:\n",
    "\n",
    "An optimizer\n",
    "- The mechanism through which the model will update itself based\n",
    "on the training data it sees, so as to improve its performance.\n",
    "\n",
    "A loss function\n",
    "- How the model will be able to measure its performance on the\n",
    "training data, and thus how it will be able to steer itself in the right direction.\n",
    "\n",
    "Metrics \n",
    "- To monitor during training and testing—Here, we’ll only care about accuracy (the fraction of the images that were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "loss = 'sparse_categorical_crossentropy', \n",
    "metrics = ['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing step is important for preparing the data before feeding it into the neural network model. In this case, the data needs to be reshaped and scaled.\n",
    "\n",
    "First, the training images are reshaped from an array of shape `(60000, 28, 28)` to a `float32` array of shape `(60000, 28 * 28)`, which means each image is flattened into a `1D` array of length `784`. This is necessary because the Dense layer in the model expects the input to be a 1D array.\n",
    "\n",
    "Second, the pixel values of the training images are scaled from the original range of `[0, 255]` to the interval `[0, 1]`. This is important for numerical stability and to ensure that the optimization algorithm works effectively. The scaling is done by dividing each pixel value by `255`, which results in a new range of ``[0, 1]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0398 - accuracy: 0.9880\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0303 - accuracy: 0.9909\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0254 - accuracy: 0.9924\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0193 - accuracy: 0.9944\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0153 - accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f504ff91b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "This output shows the progress of training a neural network on the MNIST dataset for five epochs (passes through the entire training set).\n",
    "\n",
    "In each epoch, the network is trained on the training set, and its performance on both the training set and validation set is evaluated. The training process is divided into batches, and each batch consists of a subset of the training data. In this case, each batch contains 469 samples (images and labels) from the training set.\n",
    "\n",
    "For each epoch, the output shows the following:\n",
    "\n",
    "Epoch number: the current epoch being trained.\n",
    "- Number of batches: the total number of batches in the training set.\n",
    "- Time taken to complete the epoch: the time taken to train the network on the entire training set.\n",
    "- Training loss: the average loss (error) on the training set for this epoch.\n",
    "- Training accuracy: the fraction of correctly classified samples on the training set for this epoch.\n",
    "- The training loss and accuracy are measures of how well the network is fitting the training data. Ideally, we want the loss to decrease and the accuracy to increase as the training progresses. However, it is also possible to overfit the training data, meaning the network is too specialized to the training data and performs poorly on new, unseen data.\n",
    "\n",
    "we can see that the loss and accuracy are improving with each epoch, which is a good sign that the network is learning to classify the images correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.4068418e-11, 9.2958440e-11, 2.4980446e-07, 8.2894940e-06,\n",
       "       9.7597813e-14, 1.2963090e-10, 1.2540451e-15, 9.9999118e-01,\n",
       "       9.8126876e-09, 4.9512511e-08, 5.3135440e-10, 1.6300375e-10,\n",
       "       2.2310291e-10, 2.0224331e-10, 4.5329154e-10, 2.7056696e-10,\n",
       "       2.2426465e-10, 3.6287645e-10, 1.9821282e-10, 3.2476458e-10,\n",
       "       8.1265161e-10, 9.5413388e-10, 2.0534825e-10, 3.5990763e-10,\n",
       "       2.8844582e-10, 3.9160936e-10, 8.4111962e-10, 2.1281159e-10,\n",
       "       3.9818771e-10, 2.8402047e-10, 7.8627999e-10, 6.1344152e-10,\n",
       "       2.2745375e-10, 8.3442275e-10, 3.4400910e-10, 6.0393673e-10,\n",
       "       5.8769367e-10, 7.4654360e-10, 3.5429332e-10, 2.8068745e-10,\n",
       "       2.9011490e-10, 7.5740814e-10, 5.3753069e-10, 5.1886939e-10,\n",
       "       9.6416453e-10, 1.3065364e-09, 5.0798210e-10, 7.5555256e-10,\n",
       "       1.4646162e-10, 5.0282872e-10, 2.6863606e-10, 2.3577626e-10,\n",
       "       7.4616779e-10, 1.9066849e-10, 4.4370074e-10, 3.0298766e-10,\n",
       "       4.3487072e-10, 2.8373187e-10, 2.6345021e-10, 3.7912956e-10,\n",
       "       5.8500060e-10, 5.6418747e-10, 5.3966842e-10, 3.8058293e-10,\n",
       "       2.8578817e-10, 4.0579351e-10, 1.8638423e-10, 7.7889878e-10,\n",
       "       4.6164511e-10, 4.4208218e-10, 2.9067987e-10, 2.4692653e-10,\n",
       "       3.0841540e-10, 4.1487502e-10, 4.5617021e-10, 1.8337948e-10,\n",
       "       1.7700404e-10, 1.8514129e-10, 2.0459957e-10, 3.9311732e-10,\n",
       "       5.3138277e-10, 3.2447914e-10, 1.2748443e-10, 5.8997357e-10,\n",
       "       8.7847468e-10, 6.9320710e-10, 5.2143295e-10, 5.6764915e-10,\n",
       "       2.6421509e-10, 5.0749982e-10, 1.9047185e-10, 5.4660820e-10,\n",
       "       2.9562933e-10, 1.8972023e-10, 4.7396670e-10, 4.8608834e-10,\n",
       "       3.2398687e-10, 4.5921514e-10, 2.2489262e-10, 7.7468804e-10,\n",
       "       1.3192014e-10, 2.8834957e-10, 8.0235520e-11, 8.0455154e-10,\n",
       "       1.2015429e-10, 6.7819722e-10, 6.1084598e-10, 2.7816549e-10,\n",
       "       4.1418557e-10, 4.4484980e-10, 2.5846009e-10, 5.5793048e-10,\n",
       "       1.3598481e-09, 4.1313936e-10, 5.5201971e-10, 9.8618602e-10,\n",
       "       3.3957998e-10, 8.1289342e-10, 6.1619848e-10, 3.1481104e-10,\n",
       "       1.8406877e-10, 9.0315933e-10, 1.3543987e-10, 7.5648121e-10,\n",
       "       2.6177721e-10, 3.5133374e-10, 5.4638200e-10, 2.8982841e-10,\n",
       "       1.2758909e-09, 5.1469795e-10, 5.5192600e-10, 6.3904970e-10,\n",
       "       1.3237864e-10, 1.6066658e-09, 4.0808321e-10, 1.9514206e-10,\n",
       "       4.3108919e-10, 1.8434458e-10, 2.0174284e-10, 1.8486922e-10,\n",
       "       8.6417257e-10, 1.2375962e-09, 9.9098285e-10, 5.1516152e-10,\n",
       "       4.0376150e-10, 2.4678998e-10, 1.8336969e-10, 6.3763983e-10,\n",
       "       8.0422169e-10, 6.4317063e-10, 6.9364092e-10, 8.1965351e-10,\n",
       "       7.8634599e-10, 8.9508034e-10, 9.8656416e-10, 4.2657913e-10,\n",
       "       6.9051764e-10, 9.7543118e-10, 4.3214296e-10, 5.8478083e-10,\n",
       "       5.2922022e-10, 3.8503756e-10, 2.7476696e-10, 5.5026944e-10,\n",
       "       2.0936684e-10, 4.0845388e-10, 4.3170961e-10, 1.3170425e-09,\n",
       "       3.4429726e-10, 2.7039773e-10, 8.7084573e-10, 2.8056327e-10,\n",
       "       3.6268685e-10, 3.9925621e-10, 2.7395269e-10, 3.8647671e-10,\n",
       "       3.1004860e-10, 7.5060286e-10, 6.4341849e-10, 1.2682215e-09,\n",
       "       5.0164661e-10, 3.0301772e-10, 5.6189470e-10, 5.4829041e-10,\n",
       "       1.0795947e-09, 4.5999712e-10, 5.6725735e-10, 2.4216393e-10,\n",
       "       1.1105026e-09, 1.1877582e-09, 4.1725734e-10, 6.7905670e-10,\n",
       "       7.3454487e-10, 2.4392455e-10, 3.7394718e-10, 1.3327401e-09,\n",
       "       5.0433574e-10, 2.2622285e-10, 5.9233463e-10, 3.8084727e-10,\n",
       "       2.9438466e-10, 3.9723344e-10, 4.6434206e-10, 4.2621806e-10,\n",
       "       6.3440442e-10, 2.4787594e-10, 1.3754650e-10, 2.3434918e-10,\n",
       "       3.4595346e-10, 1.5642951e-09, 2.4048252e-10, 2.8960129e-10,\n",
       "       2.5702018e-10, 2.4792465e-10, 3.8949230e-10, 2.4060914e-10,\n",
       "       8.9565078e-10, 5.5046467e-10, 1.6695977e-09, 1.2631471e-09,\n",
       "       2.7415917e-10, 3.5502051e-10, 1.1522955e-09, 3.1511441e-10,\n",
       "       1.4621766e-10, 3.0074104e-10, 1.2121668e-09, 4.7219811e-10,\n",
       "       6.4452765e-10, 4.4634393e-10, 4.4940557e-10, 5.1843313e-10,\n",
       "       4.7557308e-10, 1.7995520e-09, 7.6623974e-10, 5.0365323e-10,\n",
       "       2.1367601e-09, 4.1856460e-10, 2.0457032e-10, 1.3838257e-09,\n",
       "       1.1062083e-10, 2.0798692e-10, 3.3612985e-10, 5.4258109e-10,\n",
       "       1.3871840e-10, 3.3823222e-10, 9.0982805e-10, 9.6588371e-10,\n",
       "       1.1282421e-09, 1.3371496e-10, 1.3262739e-09, 4.6164511e-10,\n",
       "       4.0183618e-10, 5.8126132e-10, 1.3217459e-09, 4.8131860e-10,\n",
       "       5.8142546e-10, 1.8351350e-10, 2.8483366e-10, 5.3489096e-10,\n",
       "       3.6895456e-10, 1.7854039e-10, 8.4941282e-10, 4.9869686e-10,\n",
       "       1.7447079e-09, 7.1017947e-10, 7.0612743e-10, 2.9674110e-10,\n",
       "       3.5874595e-10, 6.2668581e-10, 5.8976091e-10, 1.0370685e-09,\n",
       "       2.0628098e-10, 8.7190272e-10, 1.6927997e-10, 1.8347010e-10,\n",
       "       1.1800354e-09, 1.2846543e-10, 4.6624932e-10, 4.1672368e-10,\n",
       "       2.0381202e-10, 6.1993427e-10, 3.0716554e-10, 2.9055902e-10,\n",
       "       4.5047488e-10, 5.6520749e-10, 4.9523891e-10, 4.0631087e-10,\n",
       "       3.2320546e-10, 3.3317138e-10, 9.8816300e-10, 5.2358567e-10,\n",
       "       5.6209193e-10, 5.3750093e-10, 4.0896059e-10, 5.6865695e-10,\n",
       "       6.9815376e-10, 3.4350292e-10, 4.8050863e-10, 2.5388244e-10,\n",
       "       2.3386246e-10, 4.8676096e-10, 3.6931011e-10, 5.9754313e-10,\n",
       "       8.5678054e-10, 1.4810787e-09, 4.1215789e-10, 8.9349400e-10,\n",
       "       7.8581819e-10, 2.6463826e-10, 9.7171737e-10, 4.0541134e-10,\n",
       "       3.4417250e-10, 7.2925410e-10, 4.4021761e-10, 4.6957999e-10,\n",
       "       6.5874201e-10, 4.4532350e-10, 6.3829692e-10, 7.3419193e-10,\n",
       "       4.8179616e-10, 1.9484303e-10, 3.9834039e-10, 2.2204245e-10,\n",
       "       5.5528593e-10, 5.2160704e-10, 9.2613389e-10, 8.7267638e-10,\n",
       "       3.2446551e-10, 2.5186492e-10, 3.8890510e-10, 8.3450236e-10,\n",
       "       6.3515876e-10, 5.8741129e-10, 7.0855183e-10, 2.0273883e-10,\n",
       "       1.1254481e-09, 7.1109713e-10, 4.8213261e-10, 1.5530665e-09,\n",
       "       2.0717604e-10, 3.0494962e-10, 1.0070725e-09, 2.8412506e-10,\n",
       "       1.4905385e-09, 1.0111453e-09, 5.3123583e-10, 2.1310649e-10,\n",
       "       4.3525492e-10, 1.9306363e-10, 8.6241403e-10, 2.3659300e-10,\n",
       "       3.8441236e-10, 8.1244544e-10, 3.0884159e-10, 6.7126449e-10,\n",
       "       4.8689097e-10, 7.0112427e-10, 5.2205495e-10, 1.9200602e-10,\n",
       "       5.9861888e-10, 1.1385205e-10, 6.8717781e-10, 4.7516779e-10,\n",
       "       3.9861325e-10, 2.7576291e-10, 3.6118880e-10, 4.9836973e-10,\n",
       "       1.0025299e-10, 5.9282518e-10, 1.4189024e-10, 4.9035320e-10,\n",
       "       2.8304542e-10, 1.8550865e-09, 7.7162216e-10, 7.1661282e-10,\n",
       "       3.0813493e-10, 6.6018474e-10, 2.4986774e-10, 8.1952378e-10,\n",
       "       1.3637911e-09, 4.4351967e-10, 2.8187416e-10, 4.6737120e-10,\n",
       "       1.2718503e-09, 7.5295586e-10, 7.8944173e-10, 1.3292160e-10,\n",
       "       1.3629875e-09, 5.0083587e-10, 3.1596964e-10, 1.0904722e-09,\n",
       "       1.2112024e-10, 3.9944589e-10, 3.3152137e-10, 5.9809729e-10,\n",
       "       5.1548099e-10, 1.2388929e-09, 2.1463006e-10, 5.0125443e-10,\n",
       "       5.6006505e-10, 3.7231598e-10, 6.1114319e-10, 2.5523270e-10,\n",
       "       6.2675032e-10, 4.2415249e-10, 4.3648782e-10, 1.1788521e-09,\n",
       "       3.8676654e-10, 3.6884057e-10, 2.2604169e-10, 5.3630178e-10,\n",
       "       4.2697881e-10, 4.9012877e-10, 3.5815864e-10, 2.4462529e-10,\n",
       "       5.1750843e-10, 7.3794748e-10, 4.1121481e-10, 1.3607614e-09,\n",
       "       9.4740960e-10, 6.5521460e-10, 5.9887922e-10, 5.5488997e-10,\n",
       "       4.4460127e-10, 3.1264488e-10, 3.4920192e-10, 6.8268385e-10,\n",
       "       1.0663777e-10, 6.7701589e-10, 2.9242209e-10, 6.4011957e-10,\n",
       "       5.6430910e-10, 1.7580287e-10, 3.7546091e-10, 3.8327827e-10,\n",
       "       3.1390565e-10, 2.3256139e-10, 4.6345372e-10, 5.1489041e-10,\n",
       "       1.1946629e-09, 4.6738902e-10, 8.8957275e-10, 9.4057662e-10,\n",
       "       4.3726861e-10, 4.4966794e-10, 6.5637040e-10, 1.1529236e-10,\n",
       "       4.7225845e-10, 4.0226714e-10, 4.3388396e-10, 7.9124013e-10,\n",
       "       4.1559337e-10, 4.7915683e-10, 1.2640606e-09, 4.8094784e-10,\n",
       "       4.2880943e-10, 3.0600072e-10, 5.2876314e-10, 8.7499813e-10,\n",
       "       2.5072991e-10, 2.3448507e-10, 7.9483670e-11, 4.5888507e-10,\n",
       "       6.2424022e-10, 4.1575510e-10, 2.3525426e-10, 4.7591248e-10,\n",
       "       5.7309624e-10, 6.7816613e-10, 7.2595119e-10, 1.0086835e-09,\n",
       "       1.4384566e-10, 2.0847861e-10, 4.1833315e-10, 5.9595645e-10,\n",
       "       6.0360622e-10, 3.4161723e-10, 4.2647336e-10, 4.4989271e-10,\n",
       "       6.1120148e-10, 3.5062683e-10, 2.8361663e-10, 3.5735073e-10,\n",
       "       1.0342043e-09, 1.3730908e-09, 4.1149728e-10, 1.5690852e-09,\n",
       "       5.1789056e-10, 5.0958526e-10, 6.4900563e-10, 6.0601607e-10,\n",
       "       3.1572264e-10, 2.6153069e-10, 2.4623423e-10, 1.3756677e-09,\n",
       "       3.6178796e-10, 2.4973146e-10, 5.3542071e-10, 4.0834794e-10,\n",
       "       1.1942642e-09, 6.3559581e-11, 7.4346435e-10, 8.0301998e-10,\n",
       "       9.1640090e-10, 3.8220371e-10, 3.7629252e-10, 1.2326624e-10,\n",
       "       3.1566305e-10, 7.8937251e-10, 2.0652625e-10, 7.0158845e-10],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999912"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][7]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code then prints out the first set of predictions, accesses the predicted class with the highest probability using the `argmax()` method, and also accesses the probability for the 8th class `(indexed from 0)` using the index operator `[7]`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0641 - accuracy: 0.9828\n",
      "test_acc: 0.9828000068664551\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test accuracy is 98.2 and training accuracy was 99.5, a bit lower than training accuracy is the example of model overfitting**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary \n",
    "1. Load the dataset\n",
    "2. Split it into train and test\n",
    "3. Build network architecture (define model type, layers, activtion function etc)\n",
    "4. Compilation step (optimizer, loss, metrics)\n",
    "5. Preprocessing the data to feed the neural network (reshaping)\n",
    "6. Model fitting\n",
    "7. Predictions\n",
    "8. Evaluating the model onto the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
